{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import librarries needed for LeNet implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import MNIST Data set available in keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 No. of training images\n",
      "10000 No. of test images\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# convert type to float32\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'No. of training images')\n",
    "print(x_test.shape[0], 'No. of test images')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model using keras commands\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the LeNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 307s 5ms/step - loss: 0.2581 - acc: 0.9205 - val_loss: 0.0566 - val_acc: 0.9828\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 277s 5ms/step - loss: 0.0847 - acc: 0.9748 - val_loss: 0.0391 - val_acc: 0.9869\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 276s 5ms/step - loss: 0.0629 - acc: 0.9813 - val_loss: 0.0321 - val_acc: 0.9894\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 272s 5ms/step - loss: 0.0526 - acc: 0.9839 - val_loss: 0.0319 - val_acc: 0.9903\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 273s 5ms/step - loss: 0.0442 - acc: 0.9865 - val_loss: 0.0291 - val_acc: 0.9905\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 272s 5ms/step - loss: 0.0400 - acc: 0.9877 - val_loss: 0.0278 - val_acc: 0.9908\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 272s 5ms/step - loss: 0.0365 - acc: 0.9890 - val_loss: 0.0281 - val_acc: 0.9909\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 273s 5ms/step - loss: 0.0319 - acc: 0.9906 - val_loss: 0.0269 - val_acc: 0.9912\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 272s 5ms/step - loss: 0.0305 - acc: 0.9908 - val_loss: 0.0265 - val_acc: 0.9914\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 272s 5ms/step - loss: 0.0282 - acc: 0.9916 - val_loss: 0.0257 - val_acc: 0.9920\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 273s 5ms/step - loss: 0.0275 - acc: 0.9916 - val_loss: 0.0271 - val_acc: 0.9919\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 273s 5ms/step - loss: 0.0246 - acc: 0.9919 - val_loss: 0.0235 - val_acc: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b423734e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=12,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.023475631990989496\n",
      "Test accuracy: 0.9925\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model as :\n",
    "1. Weights : h5\n",
    "2. Architecture : json\n",
    "\n",
    "Load the saved files and evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Loaded model from disk\n",
      "Test loss: 0.023475631990989496\n",
      "Test accuracy: 0.9925\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# serialize model to JSON\n",
    "lenet_model_json = model.to_json()\n",
    "with open(\"lenet_model.json\", \"w\") as json_file:\n",
    "    json_file.write(lenet_model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"lenet_model_weights.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# load the saved model\n",
    "lenet_model_file = open('lenet_model.json', 'r')\n",
    "lenet_model = lenet_model_file.read()\n",
    "lenet_model_file.close()\n",
    "lenet_model = model_from_json(lenet_model)\n",
    "\n",
    "# load weights into new model\n",
    "lenet_model.load_weights(\"lenet_model_weights.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "#evaluate the loaded model\n",
    "lenet_model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "score = lenet_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model as:\n",
    "1. Weights : h5\n",
    "2. Architecture : YAML\n",
    "\n",
    "Load the saved file and evaluate accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Loaded model from disk\n",
      "Test loss: 0.023475631990989496\n",
      "Test accuracy: 0.9925\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_yaml\n",
    "\n",
    "# serialize model to JSON\n",
    "lenet_model_yaml = model.to_yaml()\n",
    "with open(\"lenet_model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(lenet_model_yaml)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"lenet_model_weights.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# load the saved model\n",
    "lenet_model_file = open('lenet_model.yaml', 'r')\n",
    "lenet_model = lenet_model_file.read()\n",
    "lenet_model_file.close()\n",
    "lenet_model = model_from_yaml(lenet_model)\n",
    "\n",
    "# load weights into new model\n",
    "lenet_model.load_weights(\"lenet_model_weights.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "#evaluate the loaded model\n",
    "lenet_model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "score = lenet_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
