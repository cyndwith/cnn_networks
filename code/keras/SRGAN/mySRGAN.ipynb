{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_epoch = 200\n",
    "batch_size = 1\n",
    "lr_init = 1e-4\n",
    "\n",
    "hr_images_path = \"Data\\DIV2K_train_HR\\DIV2K_train_HR\\*\"\n",
    "hr_images_path = glob(hr_images_path)\n",
    "hr_images_path = np.random.choice(hr_images_path, size=batch_size)\n",
    "\n",
    "\n",
    "hr_images_ds = []\n",
    "lr_images_ds = []\n",
    "\n",
    "for img_path in hr_images_path:\n",
    "    img = plt.imread(img_path)\n",
    "    print(img.dtype)\n",
    "    plt.imshow(img)\n",
    "    hr_patch = tf.random_crop(img, [256, 256, 3])\n",
    "    print(hr_patch.dtype)\n",
    "    hr_patch = np.array(hr_patch) / 127.5 - 1\n",
    "    hr_patch  = tf.image.random_flip_left_right(hr_patch)\n",
    "    lr_patch  = tf.image.resize_images(hr_patch, size=[64, 64])\n",
    "    hr_images_ds.append(hr_patch)\n",
    "    lr_images_ds.append(lr_patch)\n",
    "\n",
    "# Display the cropped image\n",
    "#train_images_ds = tf.data.Dataset.from_tensor_slices((lr_images_ds, hr_images_ds))\n",
    "#train_images_ds = train_images_ds.repeat(300)\n",
    "#train_images_ds = train_images_ds.shuffle(128)\n",
    "#train_images_ds = train_images_ds.prefetch(2048)\n",
    "#train_images_ds = train_images_ds.batch(16)\n",
    "#print(train_images_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# prepare dataset function\n",
    "\n",
    "def PREPARE_DATASET():\n",
    "    hr_images_path = \"Data\\DIV2K_train_HR\\DIV2K_train_HR\\*\"\n",
    "    hr_images_path = glob(hr_images_path)\n",
    "    \n",
    "    lr_images_ds = []\n",
    "    hr_images_ds = []\n",
    "    \n",
    "    for n in range(batch_size):\n",
    "        img_path = np.random.choice(hr_images_path, size=batch_size)\n",
    "        img = plt.imread(img_path)\n",
    "        hr_patch = tf.random_crop(img, [256, 256, 3])\n",
    "        hr_patch = tf.image.random_flip_left_right(hr_patch)\n",
    "        lr_patch = tf.image.resize_images(hr_patch, size=[64, 64, 3])\n",
    "        lr_images_ds.append(lr_patch)\n",
    "        hr_images_ds.append(hr_patch)\n",
    "    lr_images_ds = np.array(lr_images_ds)/127.5 - 1\n",
    "    hr_images_ds = np.array(hr_images_ds)/127.5 - 1\n",
    "    print(lr_images_ds.shape)\n",
    "    print(hr_images_ds.shape)\n",
    "    return hr_images_ds, lr_images_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\n",
    "from keras.layers import PReLU, LeakyReLU\n",
    "#from keras.layers import UpSampling2D, Conv2D\n",
    "#from keras.layers.convolutional import UpSamping2D, Conv2D\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow.layers as tfl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "def SRGAN_GEN(input_shape):\n",
    "    n0 = Input(input_shape)\n",
    "    n = Conv2D(64, kernel_size=9, strides=1, padding='SAME')(n0)\n",
    "    n = Activation('relu')(n)\n",
    "    tmp = n\n",
    "    \n",
    "    # Residual blocks\n",
    "    for i in range(16):\n",
    "        nn = Conv2D(64, kernel_size=3, strides=1, padding='SAME')(n)\n",
    "        nn = Activation('relu')(n)\n",
    "        nn = BatchNormalization(momentum=0.8)(nn)\n",
    "        nn = Conv2D(64, kernel_size=3, strides=1, padding='SAME')(nn)\n",
    "        nn = BatchNormalization(momentum=0.8)(n)\n",
    "        nn = Add()([n, nn])\n",
    "        n  = nn\n",
    "    \n",
    "    n = Conv2D(64, kernel_size=3, strides=1, padding='SAME')(n)\n",
    "    n = BatchNormalization(momentum=0.8)(n)\n",
    "    n = Add()([n, nn])\n",
    "    \n",
    "    n = UpSampling2D(size=2)(n)\n",
    "    n = Conv2D(256, kernel_size=3, strides=1, padding='SAME')(n)\n",
    "    n = Activation('relu')(n)\n",
    "    \n",
    "    n = UpSampling2D(size=2)(n)\n",
    "    n = Conv2D(256, kernel_size=3, strides=1, padding='SAME')(n)\n",
    "    n = Activation('relu')(n)\n",
    "    \n",
    "    nn = Conv2D(3, kernel_size=9, strides=1, padding='SAME')(n)\n",
    "    \n",
    "    GEN = Model(inputs=n0, outputs=nn, name=\"SRGAN_GENERATOR\")\n",
    "    \n",
    "    return GEN\n",
    "\n",
    "def SRGAN_DIS(input_shape):\n",
    "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
    "    gamma_init = tf.random_normal_initializer(1., 0.02)\n",
    "    \n",
    "    n0 = Input(input_shape)\n",
    "    n = Conv2D(64, kernel_size=4, strides=1, padding='SAME')(n0)\n",
    "    n = LeakyReLU(alpha=0.2)(n)\n",
    "    \n",
    "    n = Conv2D(64 * 2, kernel_size=4, strides=2, padding='SAME')(n)\n",
    "    n = LeakyReLU(alpha=0.2)(n)\n",
    "    n = Conv2D(64 * 4, kernel_size=4, strides=2, padding='SAME')(n)\n",
    "    n = LeakyReLU(alpha=0.2)(n)\n",
    "    n = BatchNormalization(momentum=0.8)(n)\n",
    "    n = Conv2D(64 * 8, kernel_size=4, strides=2, padding='SAME')(n)\n",
    "    n = LeakyReLU(alpha=0.2)(n)\n",
    "    n = BatchNormalization(momentum=0.8)(n)\n",
    "    \n",
    "    n = Conv2D(64 * 16, kernel_size=4, strides=2, padding='SAME')(n)\n",
    "    n = LeakyReLU(alpha=0.2)(n)\n",
    "    n = BatchNormalization(momentum=0.2)(n)\n",
    "    \n",
    "    n = Conv2D(64 * 32, kernel_size=4, strides=2, padding='SAME')(n)\n",
    "    n = LeakyReLU(alpha=0.2)(n)\n",
    "    n = BatchNormalization(momentum=0.8)(n)\n",
    "    \n",
    "    n = Conv2D(64 * 16, kernel_size=1, strides=1, padding='SAME')(n)\n",
    "    n = LeakyReLU(alpha=0.2)(n)\n",
    "    n = BatchNormalization(momentum=0.8)(n)\n",
    "    \n",
    "    n = Conv2D(64 * 8, kernel_size=1, strides=1, padding='SAME')(n)\n",
    "    n = LeakyReLU(alpha=0.2)(n)\n",
    "    nn = BatchNormalization(momentum=0.8)(n)\n",
    "    \n",
    "    \n",
    "    n = Conv2D(64 * 2, kernel_size=1, strides=1, padding='SAME')(nn)\n",
    "    n = LeakyReLU(alpha=0.2)(n)\n",
    "    n = BatchNormalization(momentum=0.8)(n)\n",
    "    \n",
    "    n = Conv2D(64 * 2, kernel_size=3, strides=1, padding='SAME')(n)\n",
    "    n = LeakyReLU(alpha=0.2)(n)\n",
    "    n = BatchNormalization(momentum=0.8)(n)\n",
    "    \n",
    "    n = Conv2D(64 * 8, kernel_size=3, strides=1, padding='SAME')(n)\n",
    "    n = LeakyReLU(alpha=0.2)(n)\n",
    "    n = BatchNormalization(momentum=0.8)(n)\n",
    "    \n",
    "    n = Add()([n, nn])\n",
    "    n = LeakyReLU(alpha=0.2)(n)\n",
    "    \n",
    "    no = Dense(1)(n)\n",
    "    print(no.shape)\n",
    "    DIS = Model(inputs=n0, outputs=no, name=\"SRGAN_DISCRIMINATOR\")\n",
    "    \n",
    "    return DIS\n",
    "\n",
    "\n",
    "def VGG_FEATURES(input_shape):\n",
    "    vgg = VGG19(weights=\"imagenet\")\n",
    "    # Set outputs to outputs of last conv. layer in block 3\n",
    "    # See architecture at: https://github.com/keras-team/keras/blob/master/keras/applications/vgg19.py\n",
    "    vgg.outputs = [vgg.layers[9].output]\n",
    "\n",
    "    img = Input(input_shape)\n",
    "\n",
    "    # Extract image features\n",
    "    img_features = vgg(img)\n",
    "    \n",
    "    VGG_FEATURES = Model(inputs=img, outputs=img_features, name=\"VGG_FEATURES\")\n",
    "    \n",
    "    return VGG_FEATURES\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 8, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "# define input shape\n",
    "\n",
    "# Training pipeline\n",
    "def SRGAN_BUILD(input_shape, scale):\n",
    "    # read inputs\n",
    "    lr_patch = Input(input_shape)\n",
    "    output_shape = (input_shape[0]*scale, input_shape[1]*scale, input_shape[2])\n",
    "    hr_patch = Input(input_shape)\n",
    "    \n",
    "    # create optimizer\n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "    \n",
    "    # building phase\n",
    "    \n",
    "    # use vgg feature: no training\n",
    "    vgg_feature = VGG_FEATURES(output_shape)\n",
    "    vgg_feature.trainable = False\n",
    "    vgg_feature.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    # create the discriminator model\n",
    "    srgan_dis = SRGAN_DIS(output_shape)\n",
    "    srgan_dis.compile(loss='mse', optimizer=optimizer, metrics=['accuracy']) \n",
    "    \n",
    "    # create srgan complete model\n",
    "    hr_patch = Input(output_shape)\n",
    "    lr_patch = Input(input_shape)\n",
    "    \n",
    "    srgan_gen = SRGAN_GEN(input_shape)\n",
    "    pred_hr = srgan_gen(lr_patch)\n",
    "    pred_features = vgg_feature(pred_hr)\n",
    "    srgan_dis.trainable = False\n",
    "    real = srgan_dis(pred_hr)    \n",
    "    srgan_complete = Model([lr_patch, hr_patch], [real, pred_features])\n",
    "    srgan_complete.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1], optimizer=optimizer)\n",
    "\n",
    "\n",
    "input_shape = (64, 64, 3)\n",
    "scale = 4\n",
    "SRGAN_BUILD(input_shape, scale)\n",
    "#SRGAN_TRAIN(input_shape, n_epoch=100, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 8, 8, 1)\n",
      "(?, 8, 8, 1)\n",
      "(?, 8, 8, 1)\n",
      "0\n",
      "Data\\DIV2K_train_HR\\DIV2K_train_HR\\0296.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyndwith\\Anaconda3\\envs\\cnn-networks\\lib\\site-packages\\ipykernel_launcher.py:50: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "C:\\Users\\cyndwith\\Anaconda3\\envs\\cnn-networks\\lib\\site-packages\\ipykernel_launcher.py:51: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 3)\n",
      "(1, 64, 64, 3)\n",
      "12288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyndwith\\Anaconda3\\envs\\cnn-networks\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# prepare dataset function\n",
    "\n",
    "def PREPARE_DATASET():\n",
    "    hr_images_path = 'Data\\DIV2K_train_HR\\*'\n",
    "    hr_images_path = glob(hr_images_path)\n",
    "    \n",
    "    lr_images_ds = []\n",
    "    hr_images_ds = []\n",
    "    \n",
    "    for n in range(batch_size):\n",
    "        img_path = np.random.choice(hr_images_path, size=batch_size)\n",
    "        img_path = 'Data\\\\DIV2K_train_HR\\\\0296.png'\n",
    "        print(img_path)\n",
    "        img = plt.imread(img_path)\n",
    "        hr_patch = tf.random_crop(img, [256, 256, 3])\n",
    "        hr_patch = tf.image.random_flip_left_right(hr_patch)\n",
    "        lr_patch = tf.image.resize_images(hr_patch, size=[64, 64])\n",
    "        lr_images_ds.append(lr_patch)\n",
    "        hr_images_ds.append(hr_patch)\n",
    "    \n",
    "    print(lr_images_ds)\n",
    "    lr_images_ds = np.array(lr_images_ds)/127.5 - 1\n",
    "    hr_images_ds = np.array(hr_images_ds)/127.5 - 1\n",
    "    \n",
    "    print(lr_images_ds.shape)\n",
    "    \n",
    "    return hr_images_ds, lr_images_ds\n",
    "\n",
    "import imageio\n",
    "\n",
    "def PREPARE_DATASET_2():\n",
    "    hr_images_path = 'Data\\DIV2K_train_HR\\DIV2K_train_HR\\*'\n",
    "    hr_images_path = glob(hr_images_path)\n",
    "    \n",
    "    lr_images_ds = []\n",
    "    hr_images_ds = []\n",
    "    \n",
    "    for n in range(batch_size):\n",
    "        img_path = np.random.choice(hr_images_path, size=batch_size)\n",
    "        img_path = 'Data\\\\DIV2K_train_HR\\\\DIV2K_train_HR\\\\0296.png'\n",
    "        print(img_path)\n",
    "        img = imageio.imread(img_path)\n",
    "        \n",
    "        hr_patch = scipy.misc.imresize(img, (256, 256))\n",
    "        lr_patch = scipy.misc.imresize(img, (64, 64))\n",
    "\n",
    "        lr_images_ds.append(lr_patch)\n",
    "        hr_images_ds.append(hr_patch)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(lr_images_ds)\n",
    "    lr_images_ds = np.array(lr_images_ds)/127.5 - 1\n",
    "    hr_images_ds = np.array(hr_images_ds)/127.5 - 1\n",
    "    \n",
    "    print(lr_images_ds.shape)\n",
    "    \n",
    "    return hr_images_ds, lr_images_ds\n",
    "\n",
    "\n",
    "# define input shape\n",
    "\n",
    "# Training pipeline\n",
    "def SRGAN_BUILD(input_shape, scale):\n",
    "    # read inputs\n",
    "    lr_patch = Input(input_shape)\n",
    "    output_shape = (input_shape[0]*scale, input_shape[1]*scale, input_shape[2])\n",
    "    hr_patch = Input(input_shape)\n",
    "    \n",
    "    # create optimizer\n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "    \n",
    "    # building phase\n",
    "    \n",
    "    # use vgg feature: no training\n",
    "    vgg_feature = VGG_FEATURES(output_shape)\n",
    "    vgg_feature.trainable = False\n",
    "    vgg_feature.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    # create the discriminator model\n",
    "    srgan_dis = SRGAN_DIS(output_shape)\n",
    "    srgan_dis.compile(loss='mse', optimizer=optimizer, metrics=['accuracy']) \n",
    "    \n",
    "    # create srgan complete model\n",
    "    hr_patch = Input(output_shape)\n",
    "    lr_patch = Input(input_shape)\n",
    "    \n",
    "    srgan_gen = SRGAN_GEN(input_shape)\n",
    "    pred_hr = srgan_gen(lr_patch)\n",
    "    pred_features = vgg_feature(pred_hr)\n",
    "    srgan_dis.trainable = False\n",
    "    real = srgan_dis(pred_hr)    \n",
    "    srgan_complete = Model([lr_patch, hr_patch], [real, pred_features])\n",
    "    srgan_complete.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1], optimizer=optimizer)\n",
    "\n",
    "\n",
    "input_shape = (64, 64, 3)\n",
    "scale = 4\n",
    "SRGAN_BUILD(input_shape, scale)\n",
    "#SRGAN_TRAIN(input_shape, n_epoch=100, batch_size=1)\n",
    "\n",
    "def SRGAN_TRAIN(input_shape, scale, n_epoch, batch_size):\n",
    "    # Training phase\n",
    "    output_shape = (input_shape[0]*scale, input_shape[1]*scale, input_shape[2])\n",
    "    # read inputs\n",
    "    lr_patch = Input(input_shape)\n",
    "    output_shape = (input_shape[0]*scale, input_shape[1]*scale, input_shape[2])\n",
    "    hr_patch = Input(input_shape)\n",
    "    \n",
    "    # create optimizer\n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "    \n",
    "    # building phase\n",
    "    \n",
    "    # use vgg feature: no training\n",
    "    vgg_feature = VGG_FEATURES(output_shape)\n",
    "    vgg_feature.trainable = False\n",
    "    vgg_feature.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    # create the discriminator model\n",
    "    srgan_dis = SRGAN_DIS(output_shape)\n",
    "    srgan_dis.compile(loss='mse', optimizer=optimizer, metrics=['accuracy']) \n",
    "    \n",
    "    # create srgan complete model\n",
    "    hr_patch = Input(output_shape)\n",
    "    lr_patch = Input(input_shape)\n",
    "    \n",
    "    srgan_gen = SRGAN_GEN(input_shape)\n",
    "    pred_hr = srgan_gen(lr_patch)\n",
    "    pred_features = vgg_feature(pred_hr)\n",
    "    srgan_dis.trainable = False\n",
    "    real = srgan_dis(pred_hr)\n",
    "    print(real.shape)\n",
    "    srgan_complete = Model([lr_patch, hr_patch], [real, pred_features])\n",
    "    srgan_complete.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1], optimizer=optimizer)\n",
    "    \n",
    "    for n in range(n_epoch):\n",
    "        print(n)\n",
    "        hr_patch, lr_patch = PREPARE_DATASET_2();\n",
    "        print(lr_patch.shape)\n",
    "        print(lr_patch.size)\n",
    "        pred_hr = srgan_gen.predict(lr_patch)\n",
    "    \n",
    "        # Train the discriminator\n",
    "        real = np.ones((batch_size,) + (8, 8, 1))\n",
    "        fake = np.zeros((batch_size,) + (8, 8, 1)) \n",
    "        dis_loss_real = srgan_dis.train_on_batch(hr_patch, real)\n",
    "        dis_loss_pred = srgan_dis.train_on_batch(pred_hr, fake)\n",
    "        dis_loss = 0.5 * np.add(dis_loss_real, dis_loss_pred)\n",
    "\n",
    "        # Train generator\n",
    "        real = np.ones((batch_size,) + (8, 8, 1))\n",
    "        real_features = vgg_feature.predict(hr_patch)\n",
    "        srgan_loss = srgan_complete.train_on_batch([lr_patch, hr_patch], [real, real_features])\n",
    "        \n",
    "        if n % 1 == 0:\n",
    "            print(\"epoch: %s\" %(n))\n",
    "\n",
    "            \n",
    "SRGAN_TRAIN(input_shape, scale=4, n_epoch=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
