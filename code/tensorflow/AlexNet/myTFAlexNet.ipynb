{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "#######################################################################\n",
    "def _print_download_progress(count, block_size, total_size):\n",
    "    \"\"\" Function used for printing the download progress.\n",
    "    Used as a call-back function in maybe_download_and_extract(). \"\"\"\n",
    "    # Percentage completion.\n",
    "    pct_complete = float(count * block_size) / total_size\n",
    "    # Limit it because rounding errors may cause it to exceed 100%.\n",
    "    pct_complete = min(1.0, pct_complete)\n",
    "    # Status-message. Note the \\r which means the line should overwrite itself.\n",
    "    msg = \"\\r- Download progress: {0:.1%}\".format(pct_complete)\n",
    "    # Print it.\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "cifar10_url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "download_dir = \"cifar-10/\"\n",
    "data_path = \"cifar-10/\"\n",
    "\n",
    "# Filename for saving the file downloaded from the internet.\n",
    "# Use the filename from the URL and add it to the download_dir.\n",
    "filename = cifar10_url.split('/')[-1]\n",
    "file_path = os.path.join(download_dir, filename)\n",
    "\n",
    "# Check if the file already exists.\n",
    "# If it exists then we assume it has also been extracted,\n",
    "# otherwise we need to download and extract it now.\n",
    "if not os.path.exists(file_path):\n",
    "    # Check if the download directory exists, otherwise create it.\n",
    "    if not os.path.exists(download_dir):\n",
    "        os.makedirs(download_dir)\n",
    "    # Download and extract the dataset\n",
    "    # Download the file from the internet.\n",
    "    file_path, _ = urllib.request.urlretrieve(url=cifar10_url,\n",
    "                                          filename=file_path,\n",
    "                                          reporthook=_print_download_progress)\n",
    "    print()\n",
    "    print(\"Download finished. Extracting files.\")\n",
    "\n",
    "    if file_path.endswith(\".zip\"):\n",
    "        # Unpack the zip-file.\n",
    "        zipfile.ZipFile(file=file_path, mode=\"r\").extractall(download_dir)\n",
    "    elif file_path.endswith((\".tar.gz\", \".tgz\")):\n",
    "        # Unpack the tar-ball.\n",
    "        tarfile.open(name=file_path, mode=\"r:gz\").extractall(download_dir)\n",
    "\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(\"Data has apparently already been downloaded and unpacked.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Image shape:  (32, 32, 3)\n",
      "No. of training images:  40000\n",
      "No. of validation images:  10000\n",
      "No. of testing images:  10000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "\n",
    "cifar10_path = os.path.join(data_path, \"cifar-10-batches-py/\")\n",
    "\n",
    "#############################################################################\n",
    "def load_images(file_path):\n",
    "    # Read images from data set\n",
    "    with open(file_path, mode='rb') as file:\n",
    "        # In Python 3.X it is important to set the encoding, otherwise an exception is raised here.\n",
    "        # Loading the data from pickle file\n",
    "        data = pickle.load(file, encoding='bytes')\n",
    "        # get the raw images\n",
    "        raw_images = data[b'data']\n",
    "        # get the class numbers for each image, convert to numpy array\n",
    "        labels = np.array(data[b'labels'])\n",
    "        # Convert the raw images from the data-files to floating-points.\n",
    "        raw_float = np.array(raw_images, dtype=float) / 255.0\n",
    "        # Reshape the array to 4-dimensions.\n",
    "        images = raw_float.reshape([-1, 3, 32, 32])\n",
    "        # Reorder the indices of the array.\n",
    "        images = images.transpose([0, 2, 3, 1])\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "#############################################################################\n",
    "def load_data(data_path):\n",
    "    num_images = 10000\n",
    "    x = 0\n",
    "    # Pre-allocate the arrays for the images and class-numbers for efficiency.\n",
    "    x_train = np.zeros(shape=[40000, 32, 32, 3], dtype=float)\n",
    "    y_train = np.zeros(shape=[40000], dtype=int)\n",
    "    # attach the filename to directory\n",
    "    train_path = os.path.join(data_path, \"data_batch_1\")\n",
    "    x_train[x: x + num_images, :], y_train[x: x + num_images] = load_images(train_path)\n",
    "    x = x + num_images\n",
    "    \n",
    "    train_path = os.path.join(data_path, \"data_batch_2\")\n",
    "    x_train[x: x + num_images, :], y_train[x: x + num_images] = load_images(train_path)\n",
    "    x = x + num_images\n",
    "    \n",
    "    train_path = os.path.join(data_path, \"data_batch_3\")\n",
    "    x_train[x: x + num_images, :], y_train[x: x + num_images] = load_images(train_path)\n",
    "    x = x + num_images\n",
    "    \n",
    "    train_path = os.path.join(data_path, \"data_batch_4\")\n",
    "    x_train[x: x + num_images, :], y_train[x: x + num_images] = load_images(train_path)\n",
    "    \n",
    "    validation_path = os.path.join(data_path, \"data_batch_5\")\n",
    "    x_validation, y_validation = load_images(validation_path)\n",
    "    \n",
    "    test_path = os.path.join(data_path, \"test_batch\")\n",
    "    x_test, y_test = load_images(test_path)\n",
    "\n",
    "    return x_train, y_train, x_validation, y_validation, x_test, y_test    \n",
    "\n",
    "X_train, y_train, X_validation, y_validation, X_test, y_test = load_data(cifar10_path)\n",
    "\n",
    "# Resize images to 224x224x3 for AlexNet\n",
    "# X_train      = numpy.ndarray(tf.image.resize_images(X_train, [224, 224]))\n",
    "# X_validation = numpy.ndarray(tf.image.resize_images(X_validation, [224, 224]))\n",
    "# X_test       = numpy.ndarray(tf.image.resize_images(X_test, [224, 224]))\n",
    "\n",
    "# Print image data set parameters\n",
    "print('Input Image shape: ', X_train[0].shape)\n",
    "print(\"No. of training images: \", len(X_train))\n",
    "print(\"No. of validation images: \", len(X_validation))\n",
    "print(\"No. of testing images: \", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing the input images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# select a random image\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "# plot the images\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "print(y_train[index])\n",
    "\n",
    "# pre-processing \n",
    "#from sklearn.utils import shuffle\n",
    "#X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement AlexNet in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "epsilon = 1e-3\n",
    "\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def AlexNet(x):    \n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # Layer 1: Convolutional. Input = . Output = .\n",
    "    # conv1_kernel = tf.Variable(tf.truncated_normal(shape=(11, 11, 3, 96), mean = mu, stddev = sigma))\n",
    "    conv1_kernel = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 96), mean = mu, stddev = sigma))\n",
    "    conv1_bias   = tf.Variable(tf.zeros(96))\n",
    "    # conv1_output = tf.nn.conv2d(x, conv1_kernel, strides=[1, 4, 4, 1], padding='SAME') + conv1_bias\n",
    "    conv1_output = tf.nn.conv2d(x, conv1_kernel, strides=[1, 4, 4, 1], padding='SAME') + conv1_bias\n",
    "    # Layer 1: Batch Normalization\n",
    "    conv1_mean, conv1_var = tf.nn.moments(conv1_output, [0])\n",
    "    conv1_scale = tf.Variable(tf.ones([96]))\n",
    "    conv1_beta  = tf.Variable(tf.zeros([96]))\n",
    "    conv1_batch_norm = tf.nn.batch_normalization(conv1_output, conv1_mean, conv1_var, conv1_beta, conv1_scale, epsilon)\n",
    "    # Layer 1: Activation.\n",
    "    conv1_act = tf.nn.relu(conv1_batch_norm)\n",
    "    # Layer 1: Pooling. Input = . Output = .\n",
    "    conv1_pool = tf.nn.max_pool(conv1_act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Layer 2: Convolutional. Input = . Output = .\n",
    "    # conv2_kernel = tf.Variable(tf.truncated_normal(shape=(5, 5, 96, 256), mean = mu, stddev = sigma))\n",
    "    conv2_kernel = tf.Variable(tf.truncated_normal(shape=(3, 3, 96, 256), mean = mu, stddev = sigma))\n",
    "    conv2_bias   = tf.Variable(tf.zeros(256))\n",
    "    conv2_output = tf.nn.conv2d(conv1_pool, conv2_kernel, strides=[1, 1, 1, 1], padding='SAME') + conv2_bias\n",
    "    # Layer 2: Batch Normalization\n",
    "    conv2_mean, conv2_var = tf.nn.moments(conv2_output, [0])\n",
    "    conv2_scale = tf.Variable(tf.ones([256]))\n",
    "    conv2_beta  = tf.Variable(tf.zeros([256]))\n",
    "    conv2_batch_norm = tf.nn.batch_normalization(conv2_output, conv2_mean, conv2_var, conv2_beta, conv2_scale, epsilon)\n",
    "    # Layer 2: Activation.\n",
    "    conv2_act = tf.nn.relu(conv2_batch_norm)\n",
    "    # Layer 2: Pooling. Input = . Output = .\n",
    "    conv2_pool = tf.nn.max_pool(conv2_act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Layer 3: Convolutional. Input = . Output = .\n",
    "    conv3_kernel = tf.Variable(tf.truncated_normal(shape=(3, 3, 256, 384), mean = mu, stddev = sigma))\n",
    "    conv3_bias   = tf.Variable(tf.zeros(384))\n",
    "    conv3_output = tf.nn.conv2d(conv2_pool, conv3_kernel, strides=[1, 1, 1, 1], padding='SAME') + conv3_bias\n",
    "    # Layer 3: Batch Normalization\n",
    "    conv3_mean, conv3_var = tf.nn.moments(conv3_output, [0])\n",
    "    conv3_scale = tf.Variable(tf.ones([384]))\n",
    "    conv3_beta  = tf.Variable(tf.zeros([384]))\n",
    "    conv3_batch_norm = tf.nn.batch_normalization(conv3_output, conv3_mean, conv3_var, conv3_beta, conv3_scale, epsilon)\n",
    "    # Layer 3: Activation.\n",
    "    conv3_act = tf.nn.relu(conv3_batch_norm)\n",
    "\n",
    "    # Layer 4: Convolutional. Input = . Output = .\n",
    "    conv4_kernel = tf.Variable(tf.truncated_normal(shape=(3, 3, 384, 384), mean = mu, stddev = sigma))\n",
    "    conv4_bias   = tf.Variable(tf.zeros(384))\n",
    "    conv4_output = tf.nn.conv2d(conv3_act, conv4_kernel, strides=[1, 1, 1, 1], padding='SAME') + conv4_bias\n",
    "    # Layer 4: Batch Normalization\n",
    "    conv4_mean, conv4_var = tf.nn.moments(conv4_output, [0])\n",
    "    conv4_scale = tf.Variable(tf.ones([384]))\n",
    "    conv4_beta  = tf.Variable(tf.zeros([384]))\n",
    "    conv4_batch_norm = tf.nn.batch_normalization(conv4_output, conv4_mean, conv4_var, conv4_beta, conv4_scale, epsilon)\n",
    "    # Layer 4: Activation.\n",
    "    conv4_act = tf.nn.relu(conv4_batch_norm)\n",
    "\n",
    "    # Layer 5: Convolutional. Input = . Output = .\n",
    "    conv5_kernel = tf.Variable(tf.truncated_normal(shape=(3, 3, 384, 384), mean = mu, stddev = sigma))\n",
    "    conv5_bias   = tf.Variable(tf.zeros(384))\n",
    "    conv5_output = tf.nn.conv2d(conv4_act, conv5_kernel, strides=[1, 1, 1, 1], padding='SAME') + conv5_bias\n",
    "    # Layer 5: Batch Normalization\n",
    "    conv5_mean, conv5_var = tf.nn.moments(conv5_output, [0])\n",
    "    conv5_scale = tf.Variable(tf.ones([384]))\n",
    "    conv5_beta  = tf.Variable(tf.zeros([384]))\n",
    "    conv5_batch_norm = tf.nn.batch_normalization(conv5_output, conv5_mean, conv5_var, conv5_beta, conv5_scale, epsilon)\n",
    "    # Layer 5: Activation.\n",
    "    conv5_act = tf.nn.relu(conv5_batch_norm)\n",
    "    # Layer 5: Pooling. Input = . Output = .\n",
    "    conv5_pool = tf.nn.max_pool(conv5_act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')    \n",
    "    \n",
    "    # Layer 6: Flatten. Input = 5x5x16. Output = 400.\n",
    "    fc0   = flatten(conv5_pool)\n",
    "    \n",
    "    # Layer 7: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_kernel = tf.Variable(tf.truncated_normal(shape=(384, 120), mean = mu, stddev = sigma))\n",
    "    fc1_bias   = tf.Variable(tf.zeros(120))\n",
    "    fc1_output = tf.matmul(fc0, fc1_kernel) + fc1_bias\n",
    "    # Layer 7: Batch Normalization\n",
    "    fc1_mean, fc1_var = tf.nn.moments(fc1_output, [0])\n",
    "    fc1_scale = tf.Variable(tf.ones([120]))\n",
    "    fc1_beta  = tf.Variable(tf.zeros([120]))\n",
    "    fc1_batch_norm = tf.nn.batch_normalization(fc1_output, fc1_mean, fc1_var, fc1_beta, fc1_scale, epsilon)    \n",
    "    # Layer 7: Activation.\n",
    "    fc1_act = tf.nn.relu(fc1_batch_norm)\n",
    "    # Layer 7: Drop out\n",
    "    fc2_act = tf.nn.dropout(fc1_act, 0.5) \n",
    "    \n",
    "    # Layer 8: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_kernel = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_bias   = tf.Variable(tf.zeros(84))\n",
    "    fc2_output = tf.matmul(fc1_act, fc2_kernel) + fc2_bias\n",
    "    # Layer 8: Batch Normalization\n",
    "    fc2_mean, fc2_var = tf.nn.moments(fc2_output, [0])\n",
    "    fc2_scale = tf.Variable(tf.ones([84]))\n",
    "    fc2_beta  = tf.Variable(tf.zeros([84]))\n",
    "    fc2_batch_norm = tf.nn.batch_normalization(fc2_output, fc2_mean, fc2_var, fc2_beta, fc2_scale, epsilon)        \n",
    "    # Layer 8: Activation.\n",
    "    fc2_act = tf.nn.relu(fc2_batch_norm)\n",
    "    # Layer 8: Drop out \n",
    "    fc2_act = tf.nn.dropout(fc2_act, 0.5) \n",
    "    \n",
    "    # Layer X: Fully Connected. Input = 400. Output = 120.\n",
    "    fc3_kernel = tf.Variable(tf.truncated_normal(shape=(84, 84), mean = mu, stddev = sigma))\n",
    "    fc3_bias   = tf.Variable(tf.zeros(84))\n",
    "    fc3_output = tf.matmul(fc2_act, fc3_kernel) + fc3_bias\n",
    "    # Layer X: Batch Normalization\n",
    "    fc3_mean, fc3_var = tf.nn.moments(fc3_output, [0])\n",
    "    fc3_scale = tf.Variable(tf.ones([84]))\n",
    "    fc3_beta  = tf.Variable(tf.zeros([84]))\n",
    "    fc3_batch_norm = tf.nn.batch_normalization(fc3_output, fc3_mean, fc3_var, fc3_beta, fc3_scale, epsilon)    \n",
    "    # Layer X: Activation.\n",
    "    fc3_act = tf.nn.relu(fc3_batch_norm)\n",
    "    # Layer X: Drop out\n",
    "    fc3_act = tf.nn.dropout(fc3_act, 0.5) \n",
    "    \n",
    "    # Layer 9: Fully Connected. Input = 84. Output = 10.\n",
    "    fc4_kernel = tf.Variable(tf.truncated_normal(shape=(84, 10), mean = mu, stddev = sigma))\n",
    "    fc4_bias   = tf.Variable(tf.zeros(10))\n",
    "    logits     = tf.matmul(fc3_act, fc4_kernel) + fc4_bias\n",
    "    \n",
    "    return logits\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 0.001\n",
    "\n",
    "logits = AlexNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Model evaluation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model\n",
    "\n",
    "Note: Saves four files\n",
    "\n",
    "1. checkpoint : \n",
    "2. lenet.data-0000-of-00001 : holding weights\n",
    "3. lenet.index\n",
    "4. lenet.meta : graph meta data for re-training\n",
    "\n",
    "Also, saves frozen model as *.pb (binary) and *.pbtxt (human readable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/AlexNet.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/AlexNet.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Training...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "EPOCHS = 1\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    model_file = Path(\"model/AlexNet.ckpt.meta\")\n",
    "    if model_file.is_file():\n",
    "        saver.restore(sess, 'model/AlexNet.ckpt')\n",
    "        print(\"Loaded model from disk\") \n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        # X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, 'model/AlexNet.ckpt')\n",
    "    tf.train.write_graph(sess.graph.as_graph_def(), '.', 'model/AlexNet.pbtxt', as_text=True)\n",
    "    tf.train.write_graph(sess.graph.as_graph_def(), '.', 'model/AlexNet.pb', as_text=False)\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save, restore and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/AlexNet.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/AlexNet.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.605\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model/AlexNet.ckpt')\n",
    "    #new_saver = tf.train.import_meta_graph('model/AlexNet.meta')\n",
    "    #new_saver.restore(sess, tf.train.latest_checkpoint('model/'))\n",
    "                \n",
    "    validation_accuracy = evaluate(X_validation, y_validation)\n",
    "    print(\"EPOCH {} ...\".format(i+1))\n",
    "    print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "    print()\n",
    "    \n",
    "    saver.save(sess, 'model/AlexNet.ckpt')\n",
    "    tf.train.write_graph(sess.graph.as_graph_def(), '.', 'model/AlexNet.pbtxt', as_text=True)\n",
    "    tf.train.write_graph(sess.graph.as_graph_def(), '.', 'model/AlexNet.pb', as_text=False)\n",
    "    \n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/AlexNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/AlexNet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.455\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('model/'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
