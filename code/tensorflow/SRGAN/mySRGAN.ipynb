{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# images: 800\n",
      "(1404, 2040, 3)\n",
      "(351, 510, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "# Input setup\n",
    "# Prepare Data\n",
    "dataset = \"Data\\DIV2K_train_HR\\DIV2K_train_HR\"\n",
    "hr_image_filenames = os.listdir(dataset)  # print(hr_image_filenames)\n",
    "hr_image_dir  = os.path.join(os.getcwd(), dataset)  # print(data_dir)\n",
    "hr_image_data = glob.glob(os.path.join(hr_image_dir,\"*.png\")) # print(data)\n",
    "dataset = \"Data\\DIV2K_train_LR_bicubic_X4\\DIV2K_train_LR_bicubic\\X4\"\n",
    "lr_image_filenames = os.listdir(dataset)  # print(hr_image_filenames)\n",
    "lr_image_dir  = os.path.join(os.getcwd(), dataset)  # print(data_dir)\n",
    "lr_image_data = glob.glob(os.path.join(lr_image_dir,\"*.png\")) # print(data)\n",
    "\n",
    "hr_images = []\n",
    "lr_images = []\n",
    "\n",
    "print(\"# images:\", len(hr_image_data))\n",
    "\n",
    "for i in range(5): #range(len(data)):\n",
    "    hr_image = imageio.imread(hr_image_data[i]).astype(np.float)\n",
    "    hr_images.append(hr_image)\n",
    "    lr_image = imageio.imread(lr_image_data[i]).astype(np.float)\n",
    "    lr_images.append(lr_image)\n",
    "\n",
    "print(hr_images[0].shape)\n",
    "print(lr_images[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorlayer as tfl\n",
    "\n",
    "# Generator Model\n",
    "def SRGAN_GEN(input_image):\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    # Layer 1: Convolution Input =. Output=.\n",
    "    conv1_kernel = tf.Variable(tf.truncated_normal(shape=(3, 3, 3, 64), mean = mu, stddev = sigma))\n",
    "    conv1_bias   = tf.Variable(tf.zeros(64))\n",
    "    conv1_output = tf.nn.conv2d(input_image, conv1_kernel, strides=[1, 1, 1, 1], act=tf.nn.relu, padding='SAME') + conv1_bias\n",
    "    conv1_act = tf.nn.relu(conv1_output)\n",
    "    tmp_conv_act = conv1_act\n",
    "    # B residual blocks\n",
    "    for i in range(16):\n",
    "        # Layer: Convolution\n",
    "        tmp_conv_kernel = tf.Variable(tf.truncated_normal(shape=(3, 3, 3, 64), mean = mu, stddev= sigma))\n",
    "        tmp_conv_bias   = tf.Variable(tf.zeros(64))\n",
    "        tmp_conv_output = tf.nn.conv2d(tmp_conv_act, tmp_conv_kernel, strides=[1, 1, 1, 1], padding='SAME') + tmp_conv_bias       \n",
    "        # Layer: Batch Normalization\n",
    "        tmp_conv_mean, tmp_conv_var = tf.nn.moments(tmp_conv_output, [0])\n",
    "        tmp_conv_scale = tf.Variable(tf.ones([64]))\n",
    "        tmp_conv_beta  = tf.Variable(tf.zeros([64]))\n",
    "        tmp_conv_bn = tf.nn.batch_normalization(tmp_conv_output, tmp_conv_mean, tmp_conv_var, tmp_conv_beta, tmp_conv_scale, epsilon)        \n",
    "        # Layer: Convolution\n",
    "        tmp_conv_kernel = tf.Variable(tf.truncated_normal(shape=(3, 3, 3, 64), mean = mu, stddev= sigma))\n",
    "        tmp_conv_bias   = tf.Variable(tf.zeros(64))\n",
    "        tmp_conv_output = tf.nn.conv2d(tmp_conv_bn, tmp_conv_kernel, strides=[1, 1, 1, 1], padding='SAME') + tmp_conv_bias       \n",
    "        # Layer: Batch Normalization\n",
    "        tmp_conv_mean, tmp_conv_var = tf.nn.moments(tmp_conv_output, [0])\n",
    "        tmp_conv_scale = tf.Variable(tf.ones([64]))\n",
    "        tmp_conv_beta  = tf.Variable(tf.zeros([64]))\n",
    "        tmp_conv_bn = tf.nn.batch_normalization(tmp_conv_output, tmp_conv_mean, tmp_conv_var, tmp_conv_beta, tmp_conv_scale, epsilon)        \n",
    "        # Layer: Elementwise Add\n",
    "        tmp_eltwise_out = tf.math.add([tmp_conv_act, tmp_conv_bn])\n",
    "        tmp_conv_act = tmp_eltwise_out\n",
    "    \n",
    "    # Layer: Convolution\n",
    "    conv_kernel = tf.Variable(tf.truncated_normal(shape=(3, 3, 3, 64), mean = mu, stddev= sigma))\n",
    "    conv_bias   = tf.Variable(tf.zeros(64))\n",
    "    conv_output = tf.nn.conv2d(tmp_conv_act, conv_kernel, strides=[1, 1, 1, 1], padding='SAME') + conv_bias       \n",
    "    # Layer: Batch Normalization\n",
    "    conv_mean, conv_var = tf.nn.moments(conv_output, [0])\n",
    "    conv_scale = tf.Variable(tf.ones([64]))\n",
    "    conv_beta  = tf.Variable(tf.zeros([64]))\n",
    "    conv_bn = tf.nn.batch_normalization(conv_output, conv_mean, conv_var, conv_beta, conv_scale, epsilon)        \n",
    "    # Layer: Eltwise operations\n",
    "    eltwise_out = tf.math.add([conv_bn, tmp_conv_act])\n",
    "    \n",
    "    # Layer: Convolution\n",
    "    conv_kernel = tf.Variable(tf.truncated_normal(shape=(3, 3, 3, 64), mean = mu, stddev= sigma))\n",
    "    conv_bias   = tf.Variable(tf.zeros(64))\n",
    "    conv_output = tf.nn.conv2d(tmp_conv_act, conv_kernel, strides=[1, 1, 1, 1], padding='SAME') + conv_bias       \n",
    "    # Layer: Sub Pixel Convolution\n",
    "    subpixconv_out = tfl.layers.SubpixelConv2d(conv_output, scale=2, n_out_channel=None, act=tf.nn.relu)\n",
    "    \n",
    "    # Layer: Convolution\n",
    "    conv_kernel = tf.Variable(tf.truncated_normal(shape=(3, 3, 3, 64), mean = mu, stddev= sigma))\n",
    "    conv_bias   = tf.Variable(tf.zeros(64))\n",
    "    conv_output = tf.nn.conv2d(subpixconv_act, conv_kernel, strides=[1, 1, 1, 1], padding='SAME') + conv_bias       \n",
    "    # Layer: Sub Pixel Convolution\n",
    "    subpixconv_out = tfl.layers.SubpixelConv2d(conv_output, scale=2, n_out_channel=None, act=tf.nn.relu)\n",
    "    \n",
    "    # Layer: Convolution\n",
    "    conv_kernel = tf.Variable(tf.truncated_normal(shape=(3, 3, 3, 64), mean = mu, stddev= sigma))\n",
    "    conv_bias   = tf.Variable(tf.zeros(64))\n",
    "    conv_output = tf.nn.conv2d(subpixconv_act, conv_kernel, strides=[1, 1, 1, 1], padding='SAME') + conv_bias       \n",
    "    \n",
    "    return conv_output\n",
    "\n",
    "\n",
    "# Discriminator\n",
    "def SRGAN_DIS(input_image):\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    # Layer 1: Convolution Input =. Output=.\n",
    "    conv1_kernel = tf.Variable(tf.truncated_normal(shape=(4, 4, 3, 64), mean = mu, stddev = sigma))\n",
    "    conv1_bias   = tf.Variable(tf.zeros(64))\n",
    "    conv1_output = tf.nn.conv2d(input_image, conv1_kernel, strides=[1, 1, 1, 1], act=None, padding='SAME') + conv1_bias\n",
    "    conv1_act    = tf.nn.leaky_relu(conv1_output, alpha=0.01) \n",
    "\n",
    "    # Layer 2: Convolution Input =. Output=.\n",
    "    conv2_kernel = tf.Variable(tf.truncated_normal(shape=(4, 4, 64, 64), mean = mu, stddev = sigma))\n",
    "    conv2_bias   = tf.Variable(tf.zeros(64))\n",
    "    conv2_output = tf.nn.conv2d(input_image, conv2_kernel, strides=[1, 2, 2, 1], act=None, padding='SAME') + conv2_bias\n",
    "    conv2_act    = tf.nn.leaky_relu(conv2_output, alpha=0.01)\n",
    "    # Layer 2: Batch Normalization\n",
    "    conv2_mean, conv2_var = tf.nn.moments(conv2_act, [0])\n",
    "    conv2_scale = tf.Variable(tf.ones([128]))\n",
    "    conv2_beta  = tf.Variable(tf.zeros([128]))\n",
    "    conv2_bn    = tf.nn.batch_normalization(conv2_act, conv2_mean, conv2_var, conv2_beta, conv2_scale, epsilon)        \n",
    "    \n",
    "    # Layer 3: Convolution Input =. Output=.\n",
    "    conv3_kernel = tf.Variable(tf.truncated_normal(shape=(4, 4, 64, 128), mean = mu, stddev = sigma))\n",
    "    conv3_bias   = tf.Variable(tf.zeros(128))\n",
    "    conv3_output = tf.nn.conv2d(input_image, conv3_kernel, strides=[1, 1, 1, 1], act=None, padding='SAME') + conv2_bias\n",
    "    conv3_act    = tf.nn.leaky_relu(conv3_output, alpha=0.01)\n",
    "    # Layer 3: Batch Normalization\n",
    "    conv3_mean, conv2_var = tf.nn.moments(conv3_act, [0])\n",
    "    conv3_scale = tf.Variable(tf.ones([128]))\n",
    "    conv3_beta  = tf.Variable(tf.zeros([128]))\n",
    "    conv3_bn    = tf.nn.batch_normalization(conv3_act, conv3_mean, conv3_var, conv3_beta, conv3_scale, epsilon)        \n",
    "    \n",
    "    # Layer 4: Convolution Input =. Output=.\n",
    "    conv4_kernel = tf.Variable(tf.truncated_normal(shape=(4, 4, 128, 128), mean = mu, stddev = sigma))\n",
    "    conv4_bias   = tf.Variable(tf.zeros(128))\n",
    "    conv4_output = tf.nn.conv2d(input_image, conv4_kernel, strides=[1, 2, 2, 1], act=None, padding='SAME') + conv2_bias\n",
    "    conv4_act    = tf.nn.leaky_relu(conv4_output, alpha=0.01)\n",
    "    # Layer 4: Batch Normalization\n",
    "    conv4_mean, conv2_var = tf.nn.moments(conv4_act, [0])\n",
    "    conv4_scale = tf.Variable(tf.ones([128]))\n",
    "    conv4_beta  = tf.Variable(tf.zeros([128]))\n",
    "    conv4_bn    = tf.nn.batch_normalization(conv4_act, conv4_mean, conv4_var, conv4_beta, conv4_scale, epsilon)   \n",
    "    \n",
    "    # Layer 5: Convolution Input =. Output=.\n",
    "    conv5_kernel = tf.Variable(tf.truncated_normal(shape=(4, 4, 128, 256), mean = mu, stddev = sigma))\n",
    "    conv5_bias   = tf.Variable(tf.zeros(256))\n",
    "    conv5_output = tf.nn.conv2d(input_image, conv5_kernel, strides=[1, 1, 1, 1], act=None, padding='SAME') + conv5_bias\n",
    "    conv5_act    = tf.nn.leaky_relu(conv5_output, alpha=0.01)\n",
    "    # Layer 5: Batch Normalization\n",
    "    conv5_mean, conv5_var = tf.nn.moments(conv5_act, [0])\n",
    "    conv5_scale = tf.Variable(tf.ones([256]))\n",
    "    conv5_beta  = tf.Variable(tf.zeros([256]))\n",
    "    conv5_bn    = tf.nn.batch_normalization(conv5_act, conv5_mean, conv5_var, conv5_beta, conv5_scale, epsilon)   \n",
    "    \n",
    "    # Layer 6: Convolution Input =. Output=.\n",
    "    conv6_kernel = tf.Variable(tf.truncated_normal(shape=(4, 4, 256, 256), mean = mu, stddev = sigma))\n",
    "    conv6_bias   = tf.Variable(tf.zeros(256))\n",
    "    conv6_output = tf.nn.conv2d(input_image, conv5_kernel, strides=[1, 2, 2, 1], act=None, padding='SAME') + conv6_bias\n",
    "    conv6_act    = tf.nn.leaky_relu(conv5_output, alpha=0.01)\n",
    "    # Layer 6: Batch Normalization\n",
    "    conv6_mean, conv6_var = tf.nn.moments(conv6_act, [0])\n",
    "    conv6_scale = tf.Variable(tf.ones([256]))\n",
    "    conv6_beta  = tf.Variable(tf.zeros([256]))\n",
    "    conv6_bn    = tf.nn.batch_normalization(conv6_act, conv6_mean, conv6_var, conv6_beta, conv6_scale, epsilon)   \n",
    "    \n",
    "    # Layer 7: Convolution Input =. Output=.\n",
    "    conv7_kernel = tf.Variable(tf.truncated_normal(shape=(4, 4, 256, 512), mean = mu, stddev = sigma))\n",
    "    conv7_bias   = tf.Variable(tf.zeros(512))\n",
    "    conv7_output = tf.nn.conv2d(input_image, conv7_kernel, strides=[1, 1, 1, 1], act=None, padding='SAME') + conv7_bias\n",
    "    conv7_act    = tf.nn.leaky_relu(conv7_output, alpha=0.01)\n",
    "    # Layer 7: Batch Normalization\n",
    "    conv7_mean, conv6_var = tf.nn.moments(conv7_act, [0])\n",
    "    conv7_scale = tf.Variable(tf.ones([512]))\n",
    "    conv7_beta  = tf.Variable(tf.zeros([512]))\n",
    "    conv7_bn    = tf.nn.batch_normalization(conv7_act, conv7_mean, conv7_var, conv7_beta, conv7_scale, epsilon)\n",
    "    \n",
    "    # Layer 8: Convolution Input =. Output=.\n",
    "    conv8_kernel = tf.Variable(tf.truncated_normal(shape=(4, 4, 512, 512), mean = mu, stddev = sigma))\n",
    "    conv8_bias   = tf.Variable(tf.zeros(512))\n",
    "    conv8_output = tf.nn.conv2d(input_image, conv8_kernel, strides=[1, 2, 2, 1], act=None, padding='SAME') + conv8_bias\n",
    "    conv8_act    = tf.nn.leaky_relu(conv8_output, alpha=0.01)\n",
    "    # Layer 8: Batch Normalization\n",
    "    conv8_mean, conv8_var = tf.nn.moments(conv8_act, [0])\n",
    "    conv8_scale = tf.Variable(tf.ones([512]))\n",
    "    conv8_beta  = tf.Variable(tf.zeros([512]))\n",
    "    conv8_bn    = tf.nn.batch_normalization(conv8_act, conv8_mean, conv8_var, conv8_beta, conv8_scale, epsilon)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SRGAN_d(input_images, is_train=True, reuse=False):\n",
    "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
    "    b_init = None  # tf.constant_initializer(value=0.0)\n",
    "    gamma_init = tf.random_normal_initializer(1., 0.02)\n",
    "    df_dim = 64\n",
    "    lrelu = lambda x: tl.act.lrelu(x, 0.2)\n",
    "    with tf.variable_scope(\"SRGAN_d\", reuse=reuse):\n",
    "        tl.layers.set_name_reuse(reuse)\n",
    "        net_in = InputLayer(input_images, name='input/images')\n",
    "        net_h0 = Conv2d(net_in, df_dim, (4, 4), (2, 2), act=lrelu, padding='SAME', W_init=w_init, name='h0/c')\n",
    "\n",
    "        net_h1 = Conv2d(net_h0, df_dim * 2, (4, 4), (2, 2), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='h1/c')\n",
    "        net_h1 = BatchNormLayer(net_h1, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='h1/bn')\n",
    "        net_h2 = Conv2d(net_h1, df_dim * 4, (4, 4), (2, 2), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='h2/c')\n",
    "        net_h2 = BatchNormLayer(net_h2, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='h2/bn')\n",
    "        net_h3 = Conv2d(net_h2, df_dim * 8, (4, 4), (2, 2), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='h3/c')\n",
    "        net_h3 = BatchNormLayer(net_h3, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='h3/bn')\n",
    "        net_h4 = Conv2d(net_h3, df_dim * 16, (4, 4), (2, 2), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='h4/c')\n",
    "        net_h4 = BatchNormLayer(net_h4, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='h4/bn')\n",
    "        net_h5 = Conv2d(net_h4, df_dim * 32, (4, 4), (2, 2), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='h5/c')\n",
    "        net_h5 = BatchNormLayer(net_h5, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='h5/bn')\n",
    "        net_h6 = Conv2d(net_h5, df_dim * 16, (1, 1), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='h6/c')\n",
    "        net_h6 = BatchNormLayer(net_h6, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='h6/bn')\n",
    "        net_h7 = Conv2d(net_h6, df_dim * 8, (1, 1), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='h7/c')\n",
    "        net_h7 = BatchNormLayer(net_h7, is_train=is_train, gamma_init=gamma_init, name='h7/bn')\n",
    "\n",
    "        net = Conv2d(net_h7, df_dim * 2, (1, 1), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='res/c')\n",
    "        net = BatchNormLayer(net, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='res/bn')\n",
    "        net = Conv2d(net, df_dim * 2, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='res/c2')\n",
    "        net = BatchNormLayer(net, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='res/bn2')\n",
    "        net = Conv2d(net, df_dim * 8, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='res/c3')\n",
    "        net = BatchNormLayer(net, is_train=is_train, gamma_init=gamma_init, name='res/bn3')\n",
    "        net_h8 = ElementwiseLayer([net_h7, net], combine_fn=tf.add, name='res/add')\n",
    "        net_h8.outputs = tl.act.lrelu(net_h8.outputs, 0.2)\n",
    "\n",
    "        net_ho = FlattenLayer(net_h8, name='ho/flatten')\n",
    "        net_ho = DenseLayer(net_ho, n_units=1, act=tf.identity, W_init=w_init, name='ho/dense')\n",
    "        logits = net_ho.outputs\n",
    "        net_ho.outputs = tf.nn.sigmoid(net_ho.outputs)\n",
    "\n",
    "    return net_ho, logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
